{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio for SDSPhD20\n",
    "\n",
    "This notebook contains the exercises and assignments to be answered in a portfolio for the PhD course \"Social Data Science: An Applied Introduction to Machine Learning\" at Aalborg University, November 2020.\n",
    "\n",
    "Each day of the course you are given an hour to work on a portfolio with the possibility of sparring with the course lecturers. \n",
    "\n",
    "You are expected to attempt to solve the various assignments using the methods and tools taught during the course. Answers should be combined into a notebook (fx by adding answers to a copy of this one). \n",
    "\n",
    "**Note:** You are not expected to attempt to solve every single assignment. Note the different requirements for each day.\n",
    "\n",
    "#### How to hand in your portfolio notebooks\n",
    "\n",
    "You can hand in your portfolio notebooks in two ways:\n",
    "\n",
    "- Saving your notebooks in a GitHub repository and then sending the repository URL to the course organizer (Kristian Kjelmann)\n",
    "- Sharing your notebooks directly with the course organizer (Kristian Kjelmann) in Google Colab.\n",
    "\n",
    "Kristianâ€™s e-mail: kgk@adm.aau.dk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio assignments for Tuesday (unsupervised and supervised machine learning)\n",
    "\n",
    "**Requirement**: Work on solutions for *either* \"unsupervised machine learning with penguins\" or \"clustering\" *and* \"supervised machine learning with penguins\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Unsupervised machine learning with penguins\n",
    "\n",
    "The palmer penguin dataset is excellent for EDA and UML. It contains different measures for 3 species of closely related penguins from several islands in Antarctica.\n",
    "\n",
    "Let's have a look:\n",
    "\n",
    "Penguin datast: https://github.com/allisonhorst/palmerpenguins\n",
    "![penguins](https://github.com/allisonhorst/palmerpenguins/raw/master/man/figures/lter_penguins.png)\n",
    "\n",
    "![penguin_beaks](https://github.com/allisonhorst/palmerpenguins/raw/master/man/figures/culmen_depth.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The assignment\n",
    "\n",
    "1. Inspect the data with some of the standard functions you learned so far (desc, info etc.). What do we have here?\n",
    "2. Likewise, use some standard visualizations (eg. from seaborn) to express some properties of the data\n",
    "3. Create a new dataset where you scale all numeric values with the standardscaler.\n",
    "4. Perform a PCA analysis\n",
    "5. Investigate the explained variance of the components... do we see an 'elbow'?\n",
    "5. Plot the data in the space of the first two components. Maybe color it by species or island. What pattern do we see?\n",
    "6. Inspect the correlation between the components. Which variables are they mostly associated with?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard packaging\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True, rc={'figure.figsize':(10,8)})\n",
    "\n",
    "from IPython.display import HTML #Youtube embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset from GitHub - original source\n",
    "\n",
    "penguins = pd.read_csv(\"https://github.com/allisonhorst/palmerpenguins/raw/5b5891f01b52ae26ad8cb9755ec93672f49328a8/data/penguins_size.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You solutions from here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Clustering\n",
    "\n",
    "I have created a larger set of variables from the Danish Value Study from 1999. You can find data here:\n",
    "\n",
    "https://raw.githubusercontent.com/CALDISS-AAU/sdsphd20/master/datasets/value99.csv\n",
    "\n",
    "In all examples, values towards 1 is agree a lot and values towards 5 is disagree a lot.\n",
    "\n",
    "As an example: \"Does not want alchoholics as neighbors\" --> 1=does not want, 2=doesnt care\n",
    "\n",
    "Or: Trust to the military --> 1=Trust very much, 2= Trust some, 3=Trust a little 4=Does not trust at all "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![2hAEhX.md.png](https://iili.io/2hAEhX.md.png)](https://freeimage.host/i/2hAEhX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick some varibles you think is interesting and play with creating clusters. Can we explain what is going on?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Supervised machine learning with penguins\n",
    "\n",
    "This assignment uses the same data as for \"unsupervised machine learning with penguins\". \n",
    "\n",
    "If you created solutions for \"unsupervised machine learning with penguins\", jump to assignment 3.\n",
    "\n",
    "### The assignment\n",
    "\n",
    "1. Inspect the data with some of the standard functions you learned so far (desc, info etc.). What do we have here?\n",
    "2. Likewise, use some standard visualizations (eg. from seaborn) to express some properties of the data\n",
    "3. Apply stanbdard preprocessing (eg. missing values, scaling, outliers, one-hot-encoding)\n",
    "4. Split the data in a train & test sample\n",
    "5. Fit a classification model (target outcome = 'species') on the training data, and evaluate its performance on the test data.\n",
    "   * Use first a logistic regression to do so.\n",
    "   * Then, use 2-3 more complex model classes of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard packaging\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True, rc={'figure.figsize':(10,8)})\n",
    "\n",
    "from IPython.display import HTML #Youtube embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset from GitHub - original source\n",
    "\n",
    "penguins = pd.read_csv(\"https://github.com/allisonhorst/palmerpenguins/raw/5b5891f01b52ae26ad8cb9755ec93672f49328a8/data/penguins_size.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You solutions from here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Portfolio assignments for Wednesday\n",
    "\n",
    "**Requirement:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Portfolio assignments for Thursday\n",
    "\n",
    "**Requirement:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
